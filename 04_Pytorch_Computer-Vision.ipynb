{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Computer Vision Libraries in Pytorch (torchvision).\n* torchvision.datasets\n* torchvision.models\n* torchvision.transforms\n* torch.utils.data.Dataset\n* torch.utils.data.DataLoader","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# import pytorch\nimport torch\nfrom torch import nn\n\n#import torchvision\nimport torchvision\nfrom torchvision import datasets\nfrom torchvision import transforms\nfrom torchvision.transforms import ToTensor\n\n#import matplotlib for visualization\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-03-09T10:17:31.289765Z","iopub.execute_input":"2023-03-09T10:17:31.290696Z","iopub.status.idle":"2023-03-09T10:17:31.297446Z","shell.execute_reply.started":"2023-03-09T10:17:31.290646Z","shell.execute_reply":"2023-03-09T10:17:31.296256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Getting a dataset****","metadata":{}},{"cell_type":"code","source":"# training data\ntrain_data = datasets.FashionMNIST(\n    root=\"data\", # where to download data to?\n    train=True, # get all the training data\n    download=True, # download the data if it doesn't exist on disk\n    transform=ToTensor(), # images come as PIL format, we want to turn into Torch tensors \n    target_transform=None # you can transform labels as well\n)\n\n# testing data\ntest_data = datasets.FashionMNIST(\n    root=\"data\", # where to download data to?\n    train=False, # get all the training data\n    download=True, # download the data if it doesn't exist on disk\n    transform=ToTensor(), # images come as PIL format, we want to turn into Torch tensors \n    target_transform=None # you can transform labels as well\n)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T10:17:31.300168Z","iopub.execute_input":"2023-03-09T10:17:31.300641Z","iopub.status.idle":"2023-03-09T10:17:31.384498Z","shell.execute_reply.started":"2023-03-09T10:17:31.300602Z","shell.execute_reply":"2023-03-09T10:17:31.383464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_data), len(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T10:17:31.386117Z","iopub.execute_input":"2023-03-09T10:17:31.386528Z","iopub.status.idle":"2023-03-09T10:17:31.394319Z","shell.execute_reply.started":"2023-03-09T10:17:31.386490Z","shell.execute_reply":"2023-03-09T10:17:31.393220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data.classes)\nprint(train_data.class_to_idx)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T10:17:31.396619Z","iopub.execute_input":"2023-03-09T10:17:31.397598Z","iopub.status.idle":"2023-03-09T10:17:31.405122Z","shell.execute_reply.started":"2023-03-09T10:17:31.397560Z","shell.execute_reply":"2023-03-09T10:17:31.404041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image,label = train_data[0]","metadata":{"execution":{"iopub.status.busy":"2023-03-09T10:17:31.406608Z","iopub.execute_input":"2023-03-09T10:17:31.406961Z","iopub.status.idle":"2023-03-09T10:17:31.415514Z","shell.execute_reply.started":"2023-03-09T10:17:31.406926Z","shell.execute_reply":"2023-03-09T10:17:31.414578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image,label","metadata":{"execution":{"iopub.status.busy":"2023-03-09T10:17:31.417130Z","iopub.execute_input":"2023-03-09T10:17:31.417501Z","iopub.status.idle":"2023-03-09T10:17:31.434114Z","shell.execute_reply.started":"2023-03-09T10:17:31.417467Z","shell.execute_reply":"2023-03-09T10:17:31.433216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check the shape and label of our image\nimage.shape,train_data.classes[label]","metadata":{"execution":{"iopub.status.busy":"2023-03-09T10:19:18.901424Z","iopub.execute_input":"2023-03-09T10:19:18.902244Z","iopub.status.idle":"2023-03-09T10:19:18.910875Z","shell.execute_reply.started":"2023-03-09T10:19:18.902199Z","shell.execute_reply":"2023-03-09T10:19:18.909793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image.squeeze().shape","metadata":{"execution":{"iopub.status.busy":"2023-03-09T10:28:49.454205Z","iopub.execute_input":"2023-03-09T10:28:49.455208Z","iopub.status.idle":"2023-03-09T10:28:49.463204Z","shell.execute_reply.started":"2023-03-09T10:28:49.455134Z","shell.execute_reply":"2023-03-09T10:28:49.461904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Visualizing our data**","metadata":{}},{"cell_type":"code","source":"image, label = train_data[0]\nprint(f\"Image shape: {image.shape}\")\nplt.imshow(image.squeeze(),cmap=\"gray\") # image shape is [1, 28, 28] (colour channels, height, width) and in the gray scale image we have to remove extra \n                            # one dimention one by squeeze() method\nplt.title(train_data.classes[label])\nplt.axis(False)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T10:32:24.244640Z","iopub.execute_input":"2023-03-09T10:32:24.245006Z","iopub.status.idle":"2023-03-09T10:32:24.332381Z","shell.execute_reply.started":"2023-03-09T10:32:24.244973Z","shell.execute_reply":"2023-03-09T10:32:24.331063Z"},"trusted":true},"execution_count":null,"outputs":[]}]}